# ğŸ–¥ï¸ PREDICTIVE MAINTENANCE DASHBOARD (PHASE 3.7)
**Architecture & Workflow Document**
**Date:** November 27, 2025
**Status:** Planning

---

## 1. ğŸ¯ Executive Summary

This document defines the architecture and workflow for the **Predictive Maintenance Dashboard**, which serves as the central command center for the entire system. It integrates:
1.  **Real-Time Monitoring:** Visualizing sensor data streams (30s intervals).
2.  **AI Insights:** Displaying ML predictions (Failure, RUL, Anomaly) and LLM explanations.
3.  **Fleet Management:** Managing the 26+ machine profiles.
4.  **New Machine Onboarding:** A UI-driven workflow to add new machines to the system (GAN training).

**Note on Phase 4 (VLM):** The Visual Language Model (VLM) system runs independently on a Raspberry Pi for the PoC. Its data will be integrated into this dashboard in the MVP phase, but for now, we focus on the ML+LLM pipeline.

---

## 2. ğŸ—ï¸ System Architecture

### 2.1 High-Level Data Flow (PoC)

```mermaid
graph TD
    A[ğŸ“‚ Sensor Data File] -->|Read every 30s| B(ğŸ”„ Data Simulator Script)
    B -->|JSON Payload| C{ğŸ§  Integrated Prediction System}
    
    subgraph "Backend (Local PC)"
        C -->|1. Predict| D[ğŸ¤– ML Models]
        D -->|2. Context| E[ğŸ“š RAG Knowledge Base]
        E -->|3. Explain| F[ğŸ¦™ Llama 3.1 LLM]
        F -->|4. Result| G[ğŸ’¾ Session State / Cache]
    end
    
    G -->|Update| H[ğŸ–¥ï¸ Streamlit Dashboard]
    
    subgraph "New Machine Workflow"
        I[ğŸ‘¤ User Input Form] -->|Config| J[âš™ï¸ GAN Training Pipeline]
        J -->|New Model| D
    end
```

### 2.2 Tech Stack
*   **Frontend:** Streamlit (Python-based, rapid prototyping).
*   **Backend Logic:** `LLM/api/ml_integration.py` (Core Engine).
*   **Data Source:** Parquet/CSV files (simulating real-time streams).
*   **Refresh Rate:** 30 seconds (PoC requirement).

---

## 3. ğŸ“± Dashboard Modules & Functionalities

The dashboard will be divided into **3 Main Pages**:

### 3.1 ğŸ  Fleet Overview (Home)
**Goal:** At-a-glance status of all 26 machines.

*   **Visuals:**
    *   **Status Grid:** Cards for each machine showing ID, Status (ğŸŸ¢ Normal, ğŸ”´ Critical, ğŸŸ¡ Warning), and RUL.
    *   **Global Metrics:** Total Active Machines, Critical Alerts, Average RUL.
*   **Functionality:**
    *   Clicking a machine card navigates to the **Machine Detail View**.
    *   Auto-refresh every 30 seconds.

### 3.2 ğŸ” Machine Detail View
**Goal:** Deep dive into a specific machine's health.

*   **Real-Time Data:**
    *   **Live Charts:** Line charts for key sensors (Vibration, Temperature, Current) updating every 30s.
    *   **Current Values:** Digital readout of the latest sensor packet.
*   **AI Analysis (The "Brain"):**
    *   **Prediction Panel:**
        *   **Failure Probability:** Gauge chart (0-100%).
        *   **RUL:** Countdown timer (Days/Hours).
        *   **Anomaly Score:** Deviation metric.
    *   **LLM Explanation:** A text box displaying the *human-readable* diagnosis generated by Llama 3.1 (e.g., "High vibration detected in bearing DE, likely due to inner race wear...").
*   **Simulation Control:**
    *   "Start/Stop Simulation" button.
    *   "Trigger Fault" button (injects a fault pattern to test the AI).

### 3.3 â• New Machine Onboarding (The "Builder")
**Goal:** UI wrapper for the `GAN/WORKFLOW_TEST_NEW_MACHINE.md` process.

*   **Workflow:**
    1.  **Profile Config:** Form to input Machine ID, Type, and Sensor List.
        *   *Action:* Generates `metadata/{id}_metadata.json`.
    2.  **Seed Generation:** Button to "Generate Physics Seed".
        *   *Action:* Runs `validate_new_machine.py` (Step 1).
    3.  **Model Training:** Button to "Train TVAE Model".
        *   *Action:* Runs TVAE training script (Step 2).
        *   *Display:* Progress bar and training logs.
    4.  **Validation:** Button to "Validate & Deploy".
        *   *Action:* Generates synthetic data and runs quality checks.
        *   *Result:* Adds machine to the Fleet Overview.

---

## 4. ğŸ”„ The "30-Second Loop" Implementation

To satisfy the PoC requirement of "file-based data sent every 30 seconds", we will implement a **Session State Simulator** in Streamlit.

**Logic:**
1.  **Load Data:** On startup, load the `test.parquet` file for the selected machine.
2.  **Iterator:** Maintain a `current_index` in `st.session_state`.
3.  **Timer:** Use `st_autorefresh` or a loop to increment `current_index` every 30s.
4.  **Process:**
    *   Fetch row `df.iloc[current_index]`.
    *   Pass to `IntegratedPredictionSystem.predict_with_explanation()`.
    *   Update UI containers with the result.

---

## 5. ğŸ“‚ File Structure for Phase 3.7

We will create a new folder `dashboard/` to keep the UI logic clean.

```
dashboard/
â”œâ”€â”€ app.py                  # Main Streamlit entry point
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ fleet_view.py       # Grid view logic
â”‚   â”œâ”€â”€ machine_view.py     # Detail view & charts
â”‚   â””â”€â”€ onboarding.py       # New machine wizard
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ data_loader.py      # Reads parquet files
â”‚   â””â”€â”€ simulator.py        # Handles the 30s ticker
â””â”€â”€ assets/                 # Images/CSS
```

---

## 6. âœ… Next Steps (Immediate Action Plan)

1.  **Create Directory:** Set up `dashboard/` structure.
2.  **Backend Bridge:** Create `dashboard/utils/backend_bridge.py` to import `IntegratedPredictionSystem` from `LLM/api/`.
3.  **Simulator:** Build the basic 30s loop reading from `GAN/data/synthetic`.
4.  **UI Shell:** Build the navigation and basic layout.
